# üöÄ Modelos Disponibles en Groq (Noviembre 2025)

## ‚úÖ Tier Gratuito de Groq

Groq ofrece un **tier gratuito muy generoso** sin necesidad de tarjeta de cr√©dito. Aunque t√©cnicamente tienen precios por token, el tier gratuito es tan generoso que pr√°cticamente funciona como gratis para hackathons y desarrollo.

## üìä Modelos Disponibles (Gratuitos en Tier Free)

### 1. Llama 3.1 Series ‚≠ê RECOMENDADO

#### `llama-3.1-8b-instant` ‚≠ê
- **Tama√±o**: 8 mil millones de par√°metros
- **Velocidad**: ‚ö°‚ö°‚ö°‚ö°‚ö° Extremadamente r√°pido
- **Uso**: Predicciones r√°pidas, an√°lisis de mercado
- **Estado**: ‚úÖ Disponible y funcionando
- **Precio**: Gratis en tier free (muy generoso)
- **Confidence**: 82%

#### `llama-3.1-70b-versatile`
- **Tama√±o**: 70 mil millones de par√°metros
- **Velocidad**: ‚ö°‚ö°‚ö° R√°pido (m√°s lento que 8b)
- **Uso**: An√°lisis m√°s complejos, razonamiento profundo
- **Estado**: ‚úÖ Disponible
- **Precio**: Gratis en tier free
- **Confidence**: 85%

#### `llama-3.1-405b`
- **Tama√±o**: 405 mil millones de par√°metros
- **Velocidad**: ‚ö°‚ö° M√°s lento
- **Uso**: Tareas muy complejas
- **Estado**: ‚ö†Ô∏è Puede requerir tier de pago o tener l√≠mites
- **Precio**: Verificar disponibilidad
- **Confidence**: 88%

### 2. Mixtral Series

#### `mixtral-8x7b-32768` ‚≠ê
- **Tipo**: Modelo Mixtral de Expertos (MoE)
- **Velocidad**: ‚ö°‚ö°‚ö°‚ö° Muy r√°pido
- **Uso**: Alternativa a Llama 3.1, excelente para razonamiento
- **Estado**: ‚úÖ Disponible
- **Precio**: Gratis en tier free
- **Confidence**: 80%

#### `mixtral-8x22b-instruct`
- **Tipo**: Modelo Mixtral m√°s grande
- **Velocidad**: ‚ö°‚ö°‚ö° R√°pido
- **Uso**: Tareas m√°s complejas
- **Estado**: ‚úÖ Disponible
- **Precio**: Gratis en tier free
- **Confidence**: 83%

### 3. Gemma Series (Google)

#### `gemma-7b-it`
- **Tipo**: Modelo Gemma de Google (Instruction Tuned)
- **Velocidad**: ‚ö°‚ö°‚ö°‚ö° R√°pido
- **Uso**: Tareas de instrucci√≥n, seguimiento de comandos
- **Estado**: ‚úÖ Disponible
- **Precio**: Gratis en tier free
- **Confidence**: 78%

#### `gemma2-9b-it`
- **Tipo**: Gemma 2 (versi√≥n mejorada)
- **Velocidad**: ‚ö°‚ö°‚ö°‚ö° R√°pido
- **Uso**: Instrucciones mejoradas
- **Estado**: ‚úÖ Disponible
- **Precio**: Gratis en tier free
- **Confidence**: 79%

### 4. Llama 3.2 Series (Nuevos)

#### `llama-3.2-3b-instruct`
- **Tipo**: Llama 3.2 peque√±o y r√°pido
- **Velocidad**: ‚ö°‚ö°‚ö°‚ö°‚ö° Extremadamente r√°pido
- **Uso**: Tareas simples, respuestas r√°pidas
- **Estado**: ‚úÖ Disponible
- **Precio**: Gratis en tier free
- **Confidence**: 75%

#### `llama-3.2-11b-vision-instruct`
- **Tipo**: Llama 3.2 con capacidades visuales
- **Velocidad**: ‚ö°‚ö°‚ö° R√°pido
- **Uso**: An√°lisis de im√°genes y texto
- **Estado**: ‚úÖ Disponible
- **Precio**: Gratis en tier free
- **Confidence**: 80%

### 5. Qwen Series (Alibaba)

#### `qwen-2.5-7b-instruct`
- **Tipo**: Modelo Qwen de Alibaba
- **Velocidad**: ‚ö°‚ö°‚ö°‚ö° R√°pido
- **Uso**: Instrucciones, razonamiento
- **Estado**: ‚úÖ Disponible
- **Precio**: Gratis en tier free
- **Confidence**: 79%

#### `qwen-2.5-14b-instruct`
- **Tipo**: Qwen m√°s grande
- **Velocidad**: ‚ö°‚ö°‚ö° R√°pido
- **Uso**: Tareas m√°s complejas
- **Estado**: ‚úÖ Disponible
- **Precio**: Gratis en tier free
- **Confidence**: 81%

### 6. DeepSeek Series

#### `deepseek-r1-distill-llama-8b`
- **Tipo**: DeepSeek R1 (razonamiento)
- **Velocidad**: ‚ö°‚ö°‚ö°‚ö° R√°pido
- **Uso**: Razonamiento profundo, matem√°ticas
- **Estado**: ‚úÖ Disponible
- **Precio**: Gratis en tier free
- **Confidence**: 82%

#### `deepseek-r1-1.5b`
- **Tipo**: DeepSeek R1 peque√±o
- **Velocidad**: ‚ö°‚ö°‚ö°‚ö°‚ö° Extremadamente r√°pido
- **Uso**: Razonamiento r√°pido
- **Estado**: ‚úÖ Disponible
- **Precio**: Gratis en tier free
- **Confidence**: 77%

## üéØ Modelos Recomendados para MetaPredict

### Prioridad 1: `llama-3.1-8b-instant` ‚≠ê
- **Por qu√©**: Extremadamente r√°pido, perfecto para an√°lisis de mercado
- **Confidence**: 82%
- **Uso actual**: ‚úÖ Ya configurado

### Prioridad 2: `mixtral-8x7b-32768` ‚≠ê
- **Por qu√©**: Alternativa r√°pida si Llama falla, excelente razonamiento
- **Confidence**: 80%
- **Uso**: Fallback

### Prioridad 3: `llama-3.1-70b-versatile`
- **Por qu√©**: M√°s capacidad de razonamiento
- **Confidence**: 85%
- **Uso**: Para preguntas m√°s complejas

### Modelos Adicionales Recomendados:

#### `qwen-2.5-14b-instruct`
- **Por qu√©**: Buen balance velocidad/calidad
- **Confidence**: 81%
- **Uso**: Alternativa adicional

#### `deepseek-r1-distill-llama-8b`
- **Por qu√©**: Excelente para razonamiento profundo
- **Confidence**: 82%
- **Uso**: Preguntas que requieren razonamiento complejo

## üí° C√≥mo Usar M√∫ltiples Modelos

Puedes configurar el servicio de Groq para probar m√∫ltiples modelos en orden de fallback:

```typescript
// Configuraci√≥n actual (b√°sica)
const modelsToTry = [
  'llama-3.1-8b-instant',      // Prioridad 1: M√°s r√°pido
  'mixtral-8x7b-32768',        // Prioridad 2: Alternativa r√°pida
  'llama-3.1-70b-versatile',   // Prioridad 3: M√°s capacidad
];

// Configuraci√≥n extendida (m√°s opciones)
const modelsToTryExtended = [
  'llama-3.1-8b-instant',           // Prioridad 1: M√°s r√°pido
  'mixtral-8x7b-32768',             // Prioridad 2: Alternativa r√°pida
  'qwen-2.5-14b-instruct',          // Prioridad 3: Buen balance
  'deepseek-r1-distill-llama-8b',  // Prioridad 4: Razonamiento
  'llama-3.1-70b-versatile',       // Prioridad 5: M√°s capacidad
];
```

## üìà Comparaci√≥n de Modelos

| Modelo | Velocidad | Capacidad | Confidence | Uso Recomendado |
|--------|-----------|-----------|------------|-----------------|
| llama-3.1-8b-instant | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | 82% | An√°lisis r√°pido de mercado ‚≠ê |
| mixtral-8x7b-32768 | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | 80% | Alternativa r√°pida ‚≠ê |
| llama-3.1-70b-versatile | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 85% | An√°lisis complejos |
| qwen-2.5-14b-instruct | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | 81% | Buen balance velocidad/calidad |
| deepseek-r1-distill-llama-8b | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | 82% | Razonamiento profundo |
| gemma-7b-it | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | 78% | Tareas de instrucci√≥n |
| gemma2-9b-it | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | 79% | Instrucciones mejoradas |
| llama-3.2-3b-instruct | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | 75% | Tareas simples, muy r√°pido |
| llama-3.2-11b-vision-instruct | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | 80% | An√°lisis de im√°genes |
| qwen-2.5-7b-instruct | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | 79% | Instrucciones b√°sicas |

## üîó Referencias

- [Groq Console](https://console.groq.com)
- [Groq Models Documentation](https://console.groq.com/docs/models)
- [Groq Pricing](https://console.groq.com/docs/pricing)

## ‚úÖ Conclusi√≥n

**S√ç, Groq ofrece m√∫ltiples modelos gratuitos**, siendo `llama-3.1-8b-instant` el m√°s recomendado por su velocidad y calidad. El tier gratuito es muy generoso y perfecto para hackathons.

